{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "import warnings\n",
    "#################DATA PREPROCESSING CLASS###################3\n",
    "\n",
    "from features import FiducialDataProcess, NMF_Data\n",
    "\n",
    "TA_test_folder_name = input('INSERT NAME OF TA TEST FOLDER; make sure folder is located in /data/ repo')\n",
    "\n",
    "'''\n",
    "#This Class is in features.py\n",
    "class FiducialDataProcess(object):\n",
    "\n",
    "\tdef __init__(self, path, num_data, num_features):\n",
    "\t\tself.path = path # \n",
    "\t\tself.num_data = num_data\n",
    "\t\tself.num_features = num_features\n",
    "\t\tself.feature_data = np.zeros((num_data, num_features*(num_features-1)))#np.zeros((2500,78*77))\n",
    "\n",
    "\tdef euc_dist(self, p1, p2):\n",
    "\t\tdist = ((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)**0.5\n",
    "\t\treturn int(dist)\n",
    "\n",
    "\n",
    "\tdef printkeys(self,i):\n",
    "\t\tdata = loadmat(self.path + '{0:04}'.format(i) +  '.mat')\n",
    "\t\treturn data\n",
    "\n",
    "\tdef preprocess(self):\n",
    "\n",
    "\t\ttotal_features = []\n",
    "\t\tfor i in range(1, self.num_data+1):\n",
    "\t\t\tcurr_feature = []\n",
    "\t\t\tdata = loadmat(self.path + '{0:04}'.format(i) +  '.mat')\n",
    "\n",
    "\t\t\tif 'faceCoordinatesUnwarped' in data:\n",
    "\t\t\t\tarr = data['faceCoordinatesUnwarped']\n",
    "\t\t\telse:\n",
    "\t\t\t\tarr = data['faceCoordinates2']\n",
    "\n",
    "\t\t\tfor j in range(arr.shape[0]-1):\n",
    "\t\t\t\tfor k in range(j+1, arr.shape[0]):\n",
    "\t\t\t\t\tcurr_feature.append(self.euc_dist(arr[j],arr[k]))\n",
    "\t\t\ttotal_features.append(curr_feature)\n",
    "\t\treturn total_features\n",
    "\n",
    "\tdef return_features(self):\n",
    "\t\tt = self.preprocess()\n",
    "\t\treturn t\n",
    "\n",
    "'''\n",
    "\n",
    "####################DATA PREPROCESSING SCRIPT ########################## \n",
    "\n",
    "path = '../data/' + TA_test_folder_name + '/points/' #SPECIFY FOLDER PATH WHERE THE NEW FIDUCIAL DATAPOINTS ARE\n",
    "print(path)\n",
    "check = input('Is this path correct? Please type yes or no')\n",
    "\n",
    "if check == 'yes':\n",
    "    print('thank you')\n",
    "elif check == 'no':\n",
    "    print('example path should be ../data/TEST_SET/points/')\n",
    "    print('Please specify EXACT path where the /points/ folder is located in :')\n",
    "else:\n",
    "    print('Input error; please rerun entire script again')\n",
    "    \n",
    "print('NOTE: SCRIPT WILL NOT RUN IF PATH IS WRONG')    \n",
    "path_, dirs, files = next(os.walk(path))\n",
    "file_count = len(files)\n",
    "\n",
    "num_features = 78\n",
    "num_data = file_count\n",
    "feature_array = FiducialDataProcess(path, num_data, num_features)\n",
    "final_features = np.array(feature_array.return_features())\n",
    "\n",
    "\n",
    "############################# FEATURE ENGINEERING CLASS###########################################\n",
    "import pickle\n",
    "'''\n",
    "#this class is in features.py\n",
    "class NMF_Data(object):\n",
    "\tdef __init__(self, dat_x, dat_y):\n",
    "\t\tself.dat_x = dat_x\n",
    "\t\tself.dat_y = dat_y\n",
    "\t\tself.nmf_features = []\n",
    "\t\tself.nmf = None\n",
    "\n",
    "\tdef create_nmf(self, reduc_comp=100, test_size=500):\n",
    "\t\tx_train, x_test, y_train, y_test = train_test_split(self.dat_x, self.dat_y, random_state=1, test_size = test_size)\n",
    "\t\tprint(x_train.shape, x_test.shape)\n",
    "\t\t\n",
    "\t\tself.nmf = NMF(n_components=reduc_comp, random_state=0)\n",
    "\t\tself.nmf.fit(x_train)\n",
    "\n",
    "\t\tx_train_nmf = self.nmf.transform(x_train)\n",
    "\t\tx_test_nmf = self.nmf.transform(x_test)\n",
    "\n",
    "\t\tself.nmf_features.append(x_train_nmf)\n",
    "\t\tself.nmf_features.append(y_train)\n",
    "\t\tself.nmf_features.append(x_test_nmf)\n",
    "\t\tself.nmf_features.append(y_test)\n",
    "\n",
    "\tdef nmf_dim_reduc(self, data):\n",
    "\t\treturn self.nmf.transform(data)\n",
    "\n",
    "\tdef get_nmf_features(self):\n",
    "\t\treturn self.nmf_features\n",
    "\n",
    "\tdef save_nmf(self, filename):\n",
    "\t\tself.create_nmf()\n",
    "\t\tnp.save(filename, self.nmf_features)\n",
    "'''\n",
    "#################################### FEATURE ENGINEERING SCRIPT ##########################################\n",
    "\n",
    "print('PREPROCESS DATA STARTING')\n",
    "url1 = 'dense_data_type_and_emot.csv'\n",
    "original_data = np.genfromtxt(url1, delimiter=',')\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(original_data)\t\n",
    "features_init = original_data[:,2:]\n",
    "features = features_init / features_init.max(axis=0)\n",
    "labels = original_data[:,0:2] \n",
    "\n",
    "orig_bin_nmf_features = NMF_Data(features, labels)\n",
    "orig_bin_nmf_features.create_nmf(reduc_comp=100)\n",
    "new_bin_nmf_features = orig_bin_nmf_features.nmf_dim_reduc(final_features)\n",
    "x_test_set_bin = new_bin_nmf_features\n",
    "\n",
    "orig_emot_nmf_features = NMF_Data(features, labels)\n",
    "orig_emot_nmf_features.create_nmf(reduc_comp=300)\n",
    "new_emot_nmf_features = orig_emot_nmf_features.nmf_dim_reduc(final_features)\n",
    "x_test_set_emot = new_emot_nmf_features\n",
    "\n",
    "test_set_len = len(x_test_set_bin)\n",
    "\n",
    "print('PREPROCESS DATA HAS FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dense_data_type_and_emot.csv', header = None)\n",
    "y_label = np.array(data[[0,1]])\n",
    "data.drop(data.columns[[0,1]],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = []\n",
    "for item in list(data.columns):\n",
    "    name = 'feature' + str(int(item)-1)\n",
    "    feature.append(name)\n",
    "\n",
    "data.columns = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 243 out of 243 | elapsed: 11.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10,\n",
       "  'max_features': 40,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 50},\n",
       " 0.65)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_param_grid = {'n_estimators':[50,100,200],\n",
    "                 'max_depth':[5,10,15],\n",
    "                 'min_samples_split':np.arange(2,14,4),\n",
    "                 'max_features':np.arange(40,100,20),\n",
    "                 }\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_param_grid)\n",
    "rf_grid = GridSearchCV(rf_clf,\n",
    "                    param_grid=rf_param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=1,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "rf_grid.fit(data, y_label[:,0])\n",
    "rf_grid.best_params_, rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 432 out of 432 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.01,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 20,\n",
       "  'n_estimators': 50},\n",
       " 0.6768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbdt_param_grid = {'learning_rate':[0.01,0.1,0.5,1],\n",
    "                   'n_estimators':[50,100,200],\n",
    "                   'max_depth':[5,10,15],\n",
    "                   'max_features':np.arange(20,100,20),\n",
    "                   }\n",
    "\n",
    "gbdt_clf = GradientBoostingClassifier(**gbdt_param_grid)\n",
    "\n",
    "gbdt_grid = GridSearchCV(gbdt_clf,\n",
    "                    param_grid=gbdt_param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=1,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "gbdt_grid.fit(data, y_label[:,0])\n",
    "gbdt_grid.best_params_, gbdt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 432 out of 432 | elapsed: 272.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.5,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 10,\n",
       "  'n_estimators': 200},\n",
       " 0.6496)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "xgb_param_grid = {\n",
    "                  'max_depth':[5,10,15],\n",
    "                  #'colsample_bytree': np.linspace(0.1, 0.9, 9),\n",
    "                  #'subsample': np.linspace(0.1, 0.9, 9),\n",
    "                  'learning_rate' : [0.01,0.1,0.5,1],\n",
    "                  'n_estimators':[20,50,100,200],\n",
    "                  'max_features':np.arange(10,70,20),\n",
    "                  }\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(**xgb_param_grid)\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_clf,\n",
    "                    param_grid=xgb_param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=1,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "xgb_grid.fit(data, y_label[:,0])\n",
    "xgb_grid.best_params_, xgb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 243 out of 243 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 15,\n",
       "  'max_features': 60,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 200},\n",
       " 0.3768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_param_grid = {'n_estimators':[50,100,200],\n",
    "                 'max_depth':[5,10,15],\n",
    "                 'min_samples_split':np.arange(2,14,4),\n",
    "                 'max_features':np.arange(40,100,20),\n",
    "                 }\n",
    "\n",
    "rf_clf = RandomForestClassifier(**rf_param_grid)\n",
    "rf_grid = GridSearchCV(rf_clf,\n",
    "                    param_grid=rf_param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=1,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "rf_grid.fit(data, y_label[:,1])\n",
    "rf_grid.best_params_, rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 432 out of 432 | elapsed: 171.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.1,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 80,\n",
       "  'n_estimators': 200},\n",
       " 0.3688)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbdt_param_grid = {'learning_rate':[0.01,0.1,0.5,1],\n",
    "                   'n_estimators':[50,100,200],\n",
    "                   'max_depth':[5,10,15],\n",
    "                   'max_features':np.arange(20,100,20),\n",
    "                   }\n",
    "\n",
    "gbdt_clf = GradientBoostingClassifier(**gbdt_param_grid)\n",
    "\n",
    "gbdt_grid = GridSearchCV(gbdt_clf,\n",
    "                    param_grid=gbdt_param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=1,\n",
    "                    scoring='accuracy')\n",
    "\n",
    "gbdt_grid.fit(data, y_label[:,1])\n",
    "gbdt_grid.best_params_, gbdt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
